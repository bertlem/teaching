{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ca7628-7575-4295-9c1b-4b6c050917bc",
   "metadata": {},
   "source": [
    "# Hypothesis testing (or A/B testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d20f0-b342-4f23-987a-9f221031d37a",
   "metadata": {},
   "source": [
    "## 1. Introduction and vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d0946-a449-4fc6-883c-e120f6d5b994",
   "metadata": {},
   "source": [
    "In science, we can formulate an hypothesis (based on previous knowledge), and perform multiple experiments to verify whether the hypothesis is correct or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a88892-1114-43f0-b9d5-c884c335d5af",
   "metadata": {},
   "source": [
    "We can reject the hypothesis if we get strong, (statistically) convincing evidence that it is wrong.\n",
    "Sometimes, the evidence against the hypothesis is not (statistically) strong enough, and we fait to reject the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d2a5a-b419-4925-9dcb-f91ad93b7f8e",
   "metadata": {},
   "source": [
    "The hypothesis that there is no difference between A and B is called the **null hypothesis**.\\\n",
    "Adopting this formulation for the null hypothesis makes it easier to formulate hypotheses (we do not need previous knowledge to specify in which way A and B are different)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc3459-5771-4760-9536-cc203cd35112",
   "metadata": {},
   "source": [
    "In practice, rejecting the null hypothesis (or failing to do so) occurs via a statistical test. A statistical test requires:\n",
    "1. experimental data\n",
    "2. a null hypothesis, to reject or fail to reject\n",
    "3. an alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f93b0-4981-4ace-9a54-66cab5c98087",
   "metadata": {},
   "source": [
    "The alternative hypotheses can be as simple as the exact opposite of the null hypothesis (for instance with two datasets A and B). It becomes more difficult (and more interesting!) when the datasets are more numerous, because we can have several alternative hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db21ff-007b-4643-9314-fd4725dcc201",
   "metadata": {},
   "source": [
    "Note: In the latter case, whatever the alternative hypothesis is selected, we can only either reject or fail to reject the null hypothesis. However, the outcome might depend on the alternative hypothesis selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fb816-720d-4e44-ab6b-3cdf079795ce",
   "metadata": {},
   "source": [
    "## 2. p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b623d-f635-4811-82ff-0fde409a0503",
   "metadata": {},
   "source": [
    "### 2.1 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf2a7a9-cf75-44f1-8216-5d1323d198b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD sample vs population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419b0c8-4204-4311-a86f-0faea9d7cca6",
   "metadata": {},
   "source": [
    "**p-values** are values between 0 and 1 that indicate whether we can reject the null hypothesis, by comparing the p-value to a user-defined threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5baa9-58f8-421e-890e-63bfdc7de772",
   "metadata": {},
   "source": [
    "In practice, the threshold value for p-values is usually set at 0.05. This means that if p<0.05, we reject the null hypothesis, while if p>0.05, we fail to reject the null hypothesis.\\\n",
    "This threshold value is called **significance level** or **$\\alpha$-level**.\\\n",
    "In practice, it also means that if we repeat the experiment a large number of times, we take the wrong decision only in 5% of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748fd9f-3d52-43e4-a479-99068ac17cb0",
   "metadata": {},
   "source": [
    "Note: A small p-value although there is actually no difference between the two datasets A and B is a **False positive**.\\\n",
    "Depending on how crucial it is that we hit the correct answer (for instance, for measuring the efficiency of a given medical treatment), it is possible to use a much smaller threshold value.\\\n",
    "In more relaxed cases, it would also be possible to use larger threshold values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a613b4-d32c-4d68-b567-1e950ea09d23",
   "metadata": {},
   "source": [
    "Important note: the p-values help us distinguishing whether two samples are different. They provide no information on the extent of this difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb21f4-56b6-4091-bf2c-63e4f3e3b2ea",
   "metadata": {},
   "source": [
    "### 2.2 Effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fd1111-ebde-4de1-abfa-177c4392befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD here**effect size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ac71f-8660-4ac2-8215-33d40abca6ef",
   "metadata": {},
   "source": [
    "### 2.3 Calculating p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f89e6f-aa04-4bfc-becf-7cd3cc4becab",
   "metadata": {},
   "source": [
    "p-value is the sum of \n",
    "1. getting the desired outcome just by random chance\n",
    "2. getting an outcome equally rare \n",
    "3. getting an even rarer outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258849ad-8397-422d-8540-6ba6ca246029",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD EXPAND HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119786b6-94c8-43a4-8eb3-a35d44c41d24",
   "metadata": {},
   "source": [
    "From the above, it is very clear that the p-value is different from the probability of getting the desired outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5390a7-0d8c-49bd-96b2-2528ac19c9fe",
   "metadata": {},
   "source": [
    "We use statistical distributions for calculating p values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdc7c7-85e9-4449-9920-849d3935021b",
   "metadata": {},
   "source": [
    "### 2.4 p-hacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c794f4-d7c8-47af-9a35-99b79f87b0c1",
   "metadata": {},
   "source": [
    "#### 2.4.1 p-hacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08ea75-020a-44f0-b9e9-d6fb5ba3de59",
   "metadata": {},
   "source": [
    "1. With a given threshold, the more tests we run, the more false positives we will discover (by construction): we should end up with 5% FP with a threshold of 0.05. This is called the \"Multiple testing problem\". There are several methods to compensate for that, the most popular being the **False Discovey Rate**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a12bd9-e6a6-4fc0-8275-9a9e93ff6b33",
   "metadata": {},
   "source": [
    "2. The proper sample size has to be determined before starting the experiment, and not adjusted later on in the hope of improving p-values. To determine the sample size, we need to perform a **power analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21f218-e17b-4bee-93f9-e6ea8d621950",
   "metadata": {},
   "source": [
    "#### 2.4.2 False discovery rates (FDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f31143-0ec5-43df-8478-daa8b62d6818",
   "metadata": {},
   "source": [
    "Sometines, bad data nevertheless looks good. FDRs are a way to sort out such data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c3abe-ef20-4da1-a1c7-d83e0e5d75c8",
   "metadata": {},
   "source": [
    "Usually, data follows a distribution curve (for instance, a Gaussian distribution) where most of the data points fall relatively close to the mean value for the sample, while only a few data points lie far away from the mean value.\\\n",
    "If we draw samples from this distribution and compare them, they will be identical in most cases (the p-value of a statistical test will be > 0.05). In a few cases (up to 5% if the threshold value is set at 0.05), the samples will be considered different (the p-value of a statistical test will be < 0.05).\\\n",
    "The latter cases are called **False Positives (FP)** because the statistical test indicates that the samples are drawn from different populations, which is false.\\\n",
    "When samples are large, even 5% FP is a large absolute number (5% of 1 000 000 = 50 000)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728b225-72df-483e-9d94-0d8f174e66d9",
   "metadata": {},
   "source": [
    "A **False Discovery Rate (FDR)** evaluates the number of false positives and removes them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03abaae-b42c-4dc4-917b-7d1014d99075",
   "metadata": {},
   "source": [
    "For instance, one can compare the distribution of p-values when samples are drawn from the same distribution (the p-values are uniformly distributed) and the distribution of p-values when samples are drawn from a different distribution (the p-values are skewed towards lower p-values, with a majority of them < 0.05 by construction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c590fe-cf16-4d3e-9928-de7ff10cdb54",
   "metadata": {},
   "source": [
    "Note: In the latter case, the drawings ending up with p-values > 0.05 are called **False Negatives (FN)**: they have p-values > 0.05 although they are drawn from different distributions. The number of FNs can be reduced by increasing the size of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a99a5-587f-40c7-9ab8-f6fbbf9c81e8",
   "metadata": {},
   "source": [
    "Comparing the two distributions, it becomes possible to identify the FPs by:\n",
    "1. identifying the level of the uniform distribution.\n",
    "2. calculating the number N of potential FPs as those N drawings with p-values above the uniform distribution level.\n",
    "3- selecting the drawings with the N smallest p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aeb5c0-11f3-49ef-b306-3cf6fab4325e",
   "metadata": {},
   "source": [
    "This procedure for retrieving FPs is called the **Benjamini-Hochberg method**.\\\n",
    "It then modifies some of the p-values for FPs and places them above the 0.05 threshold, so that a large fraction of the FPs are not significant anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af891e5-fadb-4b7a-a48d-96377dcadde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD INCLUDE BH FORMULA HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d7277-7db9-4956-b2f3-a53244c062ed",
   "metadata": {},
   "source": [
    "#### 2.4.3 Statistical power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a11639-29ba-46e2-83fd-0fdb3923ce2d",
   "metadata": {},
   "source": [
    "**Statistical power** is the probability to correctly reject the null hypothesis (that is, to get a small p-value).\\\n",
    "Statistical power increases when the two distributions we draw from have little overlap, and decreases when the two distributions have a large overlap. Moreover, statistical power decreases when the sample size decreases, and increases when the sample size increases.\\\n",
    "A power of 0.9 means that the chance of *correctly* rejecting the null hypothesis is 90%. A common value for power is 0.8.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072997d-929a-4b57-8dde-b79a773f4791",
   "metadata": {},
   "source": [
    "if the p-value is small, but slightly higher than 0.05, we cannot reject the null hypothesis. Increasing the size of the sample, hoping to reach a p-value < 0.05, would be p-hacking. Performing a power analysis provides us the sample size required to conduct the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba940cfc-b52b-416e-a20c-85395c74978e",
   "metadata": {},
   "source": [
    "A **power analysis** evaluates the number of measurements to reach a sufficient statistical power.\\\n",
    "The more the distributions overlap,the larger the samples have to be in order to reach a given power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a8b0d-e91c-43e0-8b13-5e220269745b",
   "metadata": {},
   "source": [
    "A simple way to estimate the overlap between two distributions is to use their distributions and standard deviations to compute e metric called **effect size** (usually noted d). The simplest way to compute the effect size is the following, but it is possible to select other definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf291a1-eeb2-4acd-96f6-c7727b4e8359",
   "metadata": {},
   "source": [
    "$$\n",
    "d = \\frac{\\mu_B - \\mu_A}{\\sqrt{\\frac{\\sigma²_A + \\sigma²_B}{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232250a3-8299-4b6c-b4b3-29d391990e91",
   "metadata": {},
   "source": [
    "where:\n",
    "- $\\mu_A$, $\\mu_B$  are the means of the A and B distributions\n",
    "- \\$sigma_A$ and $\\sigma_B$ are the standard deviations of the A and B distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1fe7b-8b44-4828-8413-4436303a6b59",
   "metadata": {},
   "source": [
    "## 3. t-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54021b-ac90-43ec-a30e-625ec5bccdec",
   "metadata": {},
   "source": [
    "### 3.1 t-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad20ef-812d-4136-9c6b-b77c2f18d032",
   "metadata": {},
   "source": [
    "A **t-test** tests whether there is a significant difference between the means of two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee660ced-842c-42d0-a96b-7947113d44ba",
   "metadata": {},
   "source": [
    "To reject the null hypothesis, one can directly compare the calculated t-value to a table, or calculate the p-value from the t-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93fcc7-6ed3-4c0a-92eb-6c78f8051691",
   "metadata": {},
   "source": [
    "**One-sample t-tests** are used to compare the mean of a sample to a known reference mean value. The null hypothesis states that the sample's mean is equal to the reference value (the alternative being that it is not equal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbe32c-600a-4342-8790-8a1e6f26e6c1",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "where:\n",
    "- $\\bar{x}$ is the mean of the sample\n",
    "- $\\mu$ is the reference value\n",
    "- s is standard deviation of the sample\n",
    "- n is the number of elements in the sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809e87c-3f86-4cd5-ad02-5ebf19bcb000",
   "metadata": {},
   "source": [
    "**Paired t-tests** are useful when we have at our disposal *before* and *after* measurements from the same test sample, for instance before/after administrating a drug, or before/after modifying a functionality on a webpage. The null hypothesis states that the mean of the difference between the pairs is zero (the alternative being that it is not zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4862b7-878a-490d-8504-3f89138fdeb1",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\bar{x_d} - 0}{\\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "where:\n",
    "- $\\bar{x_d}$ is the mean value of the differences\n",
    "- s is standard deviation of the sample\n",
    "- n is the number of elements in the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a77492a-e0bd-47e2-939c-4a81f2912aaf",
   "metadata": {},
   "source": [
    "When we have independent samples (group A and group B), **unpaired t-tests**, also called **independent samples** t-tests are used instead. This is for instance the case when a test group is compared with a control group. The null hypothesis states that the mean values in both groups are equal (the alternative being that they are not equal)\\\n",
    "Two versions are available, one where it can be assumed that the variance of a given quantity in group A is the same as the variance of this quantity in group B, or a more conservative (=secure, robust) version where the two variances in group A and in group B are assumed to be different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad7c77-7100-4e3f-93f8-a4dd28a3c9c1",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\bar{x_1} - \\bar{x_2}}{ \\sqrt{ \\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}     }     }\n",
    "$$\n",
    "where:\n",
    "- $\\bar{x_1}$ and $\\bar{x_2}$ are the mean of the samples\n",
    "- $\\mu$ is the reference value\n",
    "- $s_1$ and $s_2$ are the standard deviations of the samples\n",
    "- $n_1$ and $n_2$ are the number of elements in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802aaef2-cf7f-47e3-9268-92da999fd6f1",
   "metadata": {},
   "source": [
    "### 3.2 Testing the required assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f791e60-0852-40dc-ac53-cb40bafc4794",
   "metadata": {},
   "source": [
    "#### 3.2.1 Normality assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c48367-dddd-4214-bbe6-a410692c49cf",
   "metadata": {},
   "source": [
    "Performing a t-test requires that the variable tested must be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6352900-ce0e-422b-83fa-7d288033046a",
   "metadata": {},
   "source": [
    "There are several methods for testing for normality:\n",
    "- the Kolmogorov-Smirnov test\n",
    "- the Shapiro-Wilk test\n",
    "- the Anderson Darling test\n",
    "- the D'Agostino-Pearson omnibus test\n",
    "The null hypothesis is that the data are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1488cf5f-fe47-45d8-83fa-d08a94869b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD ADD PYTHON EXAMPLES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c2d4f-fdb6-476a-ab1b-1192ee8f0a78",
   "metadata": {},
   "source": [
    "Note: if the p-value is smaller than 0.05, we can reject the hypothesis that the data is normally distributed. if the p-value is larger than 0.05, we can only fail to reject that the data is normally distributed. In practice, we assume that the data is normally distributed, but this is formally incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763baa80-86a4-4d4f-a8db-5da30df3a998",
   "metadata": {},
   "source": [
    "Note: in all the tests above, the p-value calculated depends on the sample size, and graphical methods are often preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682945ca-1da8-4a5c-bfab-cd479658c307",
   "metadata": {},
   "source": [
    "The first graphical method is simply to plot a histogram representing the data. However, this is not very robust (especially in the case of small samples), and plotting a quantile-quantile plot (or QQ plot) is much more robust. In a QQ plot, the data is normally distributed when the sample quantiles align on the theoretical quantiles. This method presents the advantage that it indicates which quantiles dviate from the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa911d1-2d3c-49a9-9057-cd6f2eaef485",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TBD add histogram and QQ plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d21f5-442d-4bad-a660-5f683848d6c2",
   "metadata": {},
   "source": [
    "#### 3.2.2 Equal variance assumption assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7899b40-de3c-4b78-bb4f-e9f5272c12e6",
   "metadata": {},
   "source": [
    "As mentioned above, independent t-tests require equal variance. This can be tested using a Levene's test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb916cd7-5a00-4f4d-942e-86d21b3a54e4",
   "metadata": {},
   "source": [
    "A **Levene's** test tests whether variances of several samples are the same. The null hypothesis is that the variances for several groups are equal (the alternative hypothesis being that at least one group has a different variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47288794-43ab-4042-aecc-6367af963bd9",
   "metadata": {},
   "source": [
    "$$\n",
    "L = \\frac{\\text{Number of elements - number of groups}}{\\text{number of groups} -1} - \\frac{\\sum \\text{elements per group} \\times (\\text{group mean - total mean})²}{\\sum \\text{squared deviations within individual groups}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d933e9-d868-4db7-9165-f611c6d51245",
   "metadata": {},
   "source": [
    "THe L-value calculated is equal to the F-value. Combining the F-value and the degrees of freedom, it is possible to calculate the p-value. The degrees of freedom are \n",
    "$$\n",
    "\\frac{\\text{Number of groups}-1}{\\text{Number of elements}-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562a69b-0802-445e-a937-740e42c2c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
