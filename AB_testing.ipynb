{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ca7628-7575-4295-9c1b-4b6c050917bc",
   "metadata": {},
   "source": [
    "# Hypothesis testing (or A/B testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d20f0-b342-4f23-987a-9f221031d37a",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d0946-a449-4fc6-883c-e120f6d5b994",
   "metadata": {},
   "source": [
    "In science, we can formulate an hypothesis (based on previous knowledge), and perform multiple experiments to verify whether the hypothesis is correct or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a88892-1114-43f0-b9d5-c884c335d5af",
   "metadata": {},
   "source": [
    "We can reject the hypothesis if we get strong, (statistically) convincing evidence that it is wrong.\n",
    "Sometimes, the evidence against the hypothesis is not (statistically) strong enough, and we fait to reject the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d2a5a-b419-4925-9dcb-f91ad93b7f8e",
   "metadata": {},
   "source": [
    "The hypothesis that there is no difference between A and B is called the **null hypothesis**.\\\n",
    "It makes it easier to formulate hypotheses (we do not need previous knowledge to specify in which way A and B are different)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc3459-5771-4760-9536-cc203cd35112",
   "metadata": {},
   "source": [
    "In practice, rejecting the null hypothesis (or failing to do so) occurs via a statistical test. A statistical test requires:\n",
    "1. experimental data\n",
    "2. a null hypothesis, to reject or fail to reject\n",
    "3. an alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f93b0-4981-4ace-9a54-66cab5c98087",
   "metadata": {},
   "source": [
    "The alternative hypotheses can be as simple as the exact opposite of the null hypothesis (for instance with two datasets A and B). It becomes more difficult (and more interesting!) when the datasets are more numerous, because we can have several alternative hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db21ff-007b-4643-9314-fd4725dcc201",
   "metadata": {},
   "source": [
    "Note: In the latter case, whatever the alternative hypothesis is selected, we can only either reject or fail to reject the null hypothesis. However, the outcome might depend on the alternative hypothesis selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2a7a9-cf75-44f1-8216-5d1323d198b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBD sample vs. population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fb816-720d-4e44-ab6b-3cdf079795ce",
   "metadata": {},
   "source": [
    "## 2. p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba32c951-017a-4b06-a973-8f564290731a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (248587138.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    p values are values between 0 and 1 that measure TBD\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "p values are values between 0 and 1 that measure TBD\n",
    "the closer to 0 a p value is, the more we are convinced that TBD are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0e78c-dae0-404a-ba54-667f8c2522fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b5baa9-58f8-421e-890e-63bfdc7de772",
   "metadata": {},
   "source": [
    "In practice, the threshold value is usually set at 0.05. This means that if we repeat the experiment a large number of times, we take the wrong decision only in 5% of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748fd9f-3d52-43e4-a479-99068ac17cb0",
   "metadata": {},
   "source": [
    "Note: A small p-value although there is actually no difference between the two datasets A and B is a **False positive**.\\\n",
    "Depending on how crucial it is that we hit the correct answer (for instance, for measuring the efficiency of a given mediacl treatment), it is possible to use a much smaller threshold value.\\\n",
    "In more relaxed cases, it would also be possible to use larger threshold values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a613b4-d32c-4d68-b567-1e950ea09d23",
   "metadata": {},
   "source": [
    "Important note: the p-values help us distinguishing whether two samples are different. They provide no information on the extent of this difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd1111-ebde-4de1-abfa-177c4392befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd here **effect size**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ac71f-8660-4ac2-8215-33d40abca6ef",
   "metadata": {},
   "source": [
    "## 3. Calculating p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f89e6f-aa04-4bfc-becf-7cd3cc4becab",
   "metadata": {},
   "source": [
    "p-value is the sum of \n",
    "1. getting the desired outcome just by random chance\n",
    "2. getting an outcome equally rare \n",
    "3. getting an even rarer outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119786b6-94c8-43a4-8eb3-a35d44c41d24",
   "metadata": {},
   "source": [
    "From the above, it is very clear that the p-value is different from the probability of gettine the desired outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5390a7-0d8c-49bd-96b2-2528ac19c9fe",
   "metadata": {},
   "source": [
    "We use statistical distributions for calculating p values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdc7c7-85e9-4449-9920-849d3935021b",
   "metadata": {},
   "source": [
    "## 4. p-hacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08ea75-020a-44f0-b9e9-d6fb5ba3de59",
   "metadata": {},
   "source": [
    "1. With a given threshold, the more tests we run, the more false positives we will discover (by construction): we should en uo with 5% FP with a threshold of 0.05. This is called the \"Multiple testing problem\". There are several methods to compensate for that, the most popular being the **False Discovey Rate**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a12bd9-e6a6-4fc0-8275-9a9e93ff6b33",
   "metadata": {},
   "source": [
    "2. The proper sample size has to be determined before starting the experiment, and not adjusted later on in the hope of improving p-values. To determine the sample size, we need to perform a **power analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21f218-e17b-4bee-93f9-e6ea8d621950",
   "metadata": {},
   "source": [
    "## 5. False discovery rates (FDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f31143-0ec5-43df-8478-daa8b62d6818",
   "metadata": {},
   "source": [
    "Sometines, bad data nevertheless looks good. FDRs are a way to sort out such data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c3abe-ef20-4da1-a1c7-d83e0e5d75c8",
   "metadata": {},
   "source": [
    "Usually, data follows a distribution curve (for instance, a Gaussian distribution) where most of the data points fall relatively close to the mean value for the sample, while only a few data points lie far away from the mean value.\\\n",
    "If we draw samples from this distribution and compare them, they will be identical in most cases (the p-value of a statistical test will be > 0.05). In a few cases (up to 5% if the threshold value is set at 0.05), the samples will be considered different (the p-value of a statistical test will be < 0.05).\\\n",
    "The latter cases are called **False Positives (FP)** because the statistical test indicates that the samples are drawn from different populations, which is false.\\\n",
    "When samples are large, even 5% FP is a large absolute number (5% of 1 000 000 = 50 000)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728b225-72df-483e-9d94-0d8f174e66d9",
   "metadata": {},
   "source": [
    "A **False Discovery Rate (FDR)** evaluates the number of false positives and removes them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03abaae-b42c-4dc4-917b-7d1014d99075",
   "metadata": {},
   "source": [
    "For instance, one can compare the distribution of p-values when samples are drawn from the same distribution (the p-values are uniformly distributed) and the distribution of p-values when samples are drawn from a different distribution (the p-values are skewed towards lower p-values, with a majority of them < 0.05 by construction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c590fe-cf16-4d3e-9928-de7ff10cdb54",
   "metadata": {},
   "source": [
    "Note: In the latter case, the drawings ending up with p-values > 0.05 are called **False Negatives (FN)**: they have p-values > 0.05 although they are drawn from different distributions. The number of FNs can be reduced by increasing the size of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90a44c-7e29-40aa-980f-cdf9465d8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparing the two distributions, it becomes possible to identify the FPs by:\n",
    "1. identifying the level of the uniform distribution.\n",
    "2. calculating the number N of potential FPs as those N drawings with p-values above the uniform distribution level.\n",
    "3- selecting the drawings with the N smallest p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aeb5c0-11f3-49ef-b306-3cf6fab4325e",
   "metadata": {},
   "source": [
    "This procedure for retrieving FPs is called the **Benjamini-Hochberg method**.\\\n",
    "It then modifies some of the p-values for FPs and places them above the 0.05 threshold, so that a large fraction of the FPs are not significant anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af891e5-fadb-4b7a-a48d-96377dcadde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBD INCLUDE BH FORMULA HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d7277-7db9-4956-b2f3-a53244c062ed",
   "metadata": {},
   "source": [
    "## 6. Statistical power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a11639-29ba-46e2-83fd-0fdb3923ce2d",
   "metadata": {},
   "source": [
    "**Statistical power** is the probability to correctly reject the null hypothesis (that is, to get a small p-value).\\\n",
    "Statistical power increases when the two distributions we draw from have little overlap, and decreases when the two distributions have a large overlap. Moreover, statistical power decreases when the sample size decreases, and increases when the sample size increases.\\\n",
    "A power of 0.9 means that the chance of *correctly* rejecting the null hypothesis is 90%. A common value for power is 0.8.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072997d-929a-4b57-8dde-b79a773f4791",
   "metadata": {},
   "source": [
    "if the p-value is small, but slightly higher than 0.05, we cannot reject the null hypothesis. Increasing the size of the sample, hoping to reach a p-value < 0.05, would be p-hacking. Performing a power analysis provides us the sample size required to conduct the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba940cfc-b52b-416e-a20c-85395c74978e",
   "metadata": {},
   "source": [
    "A **power analysis** evaluates the number of measurements to reach a sufficient statistical power.\\\n",
    "The more the distributions overlap,the larger the samples have to be in order to reach a given power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a8b0d-e91c-43e0-8b13-5e220269745b",
   "metadata": {},
   "source": [
    "A simple way to estimate the overlap between two distributions is to use their distributions and standard deviations to compute e metric called **effect size** (usually noted d). The simplest way to compute the effect size is the following, but it os possible to select other definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf291a1-eeb2-4acd-96f6-c7727b4e8359",
   "metadata": {},
   "source": [
    "$$\n",
    "d = \\frac{\\mu_B - \\mu_A}{\\sqrt{\\frac{\\sigma²_A + \\sigma²_B}{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232250a3-8299-4b6c-b4b3-29d391990e91",
   "metadata": {},
   "source": [
    "where:\n",
    "- $\\mu_A$, $\\mu_B$  are the means of the A and B distributions\n",
    "- \\$sigma_A$ and $\\sigma_B$ are the standard deviations of the A and B distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808b932-39dc-4985-ab2e-c7205aa9d33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd4ac1-13cf-455b-9f7c-66078132fb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
